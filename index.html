<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="generator" content="Hugo 0.88.1" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
	<link rel="stylesheet" href="css/custom.css">
	<link rel="stylesheet" href="css/normalize.css">
	<title>Factorized Diffusion Models</title>
	<link href="css/bootstrap.min.css" rel="stylesheet">
</head>

<body data-new-gr-c-s-check-loaded="14.1091.0" data-gr-ext-installed="">

<div class="container" >
<header role="banner">
</header>
<main role="main">
<article itemscope itemtype="https://schema.org/BlogPosting">

<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
	<div class="text-center">
        <h3>Factorized Diffusion Models are Natural and Zero-shot Speech Synthesizers</h3>
        <p class="fst-italic mb-0">
			<br> Anonymous Authors <br><br><br>
        </p>
	</div>
	<p>
        <b>Abstract.</b> 
		While recent large-scale text-to-speech (TTS) models have achieved significant progress, they still fall shorts in speech quality, similarity, and prosody. Considering speech intricately encompasses various attributes (e.g., content, prosody, timbre, and acoustic details) that pose significant challenges to generate, a natural idea is to factorize speech into individual subspaces representing different attributes and generate them individually. Motivated by it, we propose a TTS system with novel factorized diffusion models to generate natural speech in a zero-shot way. Specifically, 1) we design a neural codec with factorized vector quantization (FVQ) to disentangle speech waveform into subspaces of content, prosody, timbre, and acoustic detail; 2) we propose a factorized diffusion model, which generates attributes in each subspace following its corresponding prompt. With this factorization design, our method can effectively and efficiently model the intricate speech in disentangled subspaces in a divide-and-conquer way, which results in better speech quality, similarity, prosody, and controllability. Experimental results show that our method outperforms state-of-the-art TTS systems on quality, similarity, prosody, and intelligibility.
		<br>
		<br>
			This page is <b> for research demonstration purposes </b> only.
		<br>

      </p>
</div>
		




<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">	
	<h2 id=Ethics-Statement style="text-align: center;">	
		Ethics Statement
	</h2>
	<p>
	</p>
</div>


</article>
</main>
</div>

</body>
</html>